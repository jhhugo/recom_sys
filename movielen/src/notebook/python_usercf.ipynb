{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'E:\\ML_study\\学习笔记\\推荐\\movielens\\ml-20m\\ratings_small.csv', engine='python')\n",
    "data = data.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data[:3500]\n",
    "test = data[3500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(r'E:\\ML_study\\学习笔记\\推荐\\movielens\\ml-20m\\ratings_train.csv', encoding='utf-8', index=False)\n",
    "test.to_csv(r'E:\\ML_study\\学习笔记\\推荐\\movielens\\ml-20m\\ratings_test.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost time 0.0018360216666666667 min\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import time\n",
    "import gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "s = time.perf_counter()\n",
    "train = pd.read_csv(r'E:\\ML_study\\学习笔记\\推荐\\movielens\\ml-20m\\ratings_train.csv', engine='python')\n",
    "test = pd.read_csv(r'E:\\ML_study\\学习笔记\\推荐\\movielens\\ml-20m\\ratings_test.csv', engine='python')\n",
    "\n",
    "def combine(data):\n",
    "    item_users = dict()\n",
    "    user_items = dict()\n",
    "    users = set()\n",
    "    data['userId'] = 'user_' + data['userId'].astype(str)\n",
    "    data['movieId'] = 'movie_' + data['movieId'].astype(str)\n",
    "    for u, item, r in data[['userId', 'movieId', 'rating']].values:\n",
    "        item_users.setdefault(item, []).append((u, r))\n",
    "        user_items.setdefault(u, []).append((item, r))\n",
    "        users.add(u)\n",
    "    del data\n",
    "    gc.collect()\n",
    "    return item_users, user_items, users\n",
    "\n",
    "train_item_users, train_user_items, train_users = combine(train)\n",
    "test_item_users, test_user_items, test_users = combine(test)\n",
    "print('cost time %s min' % ((time.perf_counter() - s) / 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from joblib import dump, load\n",
    "# dump(item_users, r'D:\\Users\\hao.guo\\比赛代码提炼\\推荐系统\\movielen\\data\\item_users.pkl')\n",
    "# dump(users, r'D:\\Users\\hao.guo\\比赛代码提炼\\推荐系统\\movielen\\data\\users.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "共现矩阵计算\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 1694/1694 [00:00<00:00, 19523.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "相似矩阵计算\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 16693.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost time 0.002101749999999984 min\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from tqdm import tqdm_notebook\n",
    "def UserSimilarity(item_users, users):\n",
    "    # build inverse table for item_users\n",
    "#     item_users = dict()\n",
    "#     users = set()\n",
    "#     for u, items in data.items():\n",
    "#         for i in items.keys():\n",
    "#             # if i not in item_users:\n",
    "#             #     item_users[i] = set()\n",
    "#             item_users.setdefault(i, set()).add(u)\n",
    "#         users.add(u)\n",
    "    #calculate co-rated items between users\n",
    "    # C = dict()\n",
    "    C = defaultdict(dict)\n",
    "    # C = np.zeros((len(item_users), len(item_users)))\n",
    "    # user items list\n",
    "    N = defaultdict(int)\n",
    "    print('共现矩阵计算')\n",
    "    for i, pairs in tqdm(item_users.items()):\n",
    "        for u, r1 in pairs:\n",
    "            N[u] += r1 ** 2\n",
    "            for v, r2 in pairs:\n",
    "                if u == v:\n",
    "                    continue\n",
    "                if v not in list(C[u]):\n",
    "                    C[u][v] = 0\n",
    "                C[u][v] += (r1 * r2 / np.log1p(len(pairs)))\n",
    "    #calculate finial similarity matrix W\n",
    "    W = defaultdict(dict)\n",
    "    print('相似矩阵计算')\n",
    "    for u, related_users in tqdm(C.items()):\n",
    "        for v, cuv in related_users.items():\n",
    "            W[u][v] = cuv / math.sqrt(N[u] * N[v])\n",
    "    return W\n",
    "s = time.perf_counter()\n",
    "W = UserSimilarity(train_item_users, train_users)\n",
    "print('cost time %s min' % ((time.perf_counter() - s) / 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('user_21', 0.19303695393600245),\n",
       " ('user_3', 0.19136694720294242),\n",
       " ('user_25', 0.1847717426269238),\n",
       " ('user_24', 0.13473512787501885),\n",
       " ('user_47', 0.11828936840773875)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(W['user_1'].items(), key=lambda p: p[1], reverse=True)[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.1328, 0.22148098732488325, 0.37422680412371134, 2.0557740410362264)\n"
     ]
    }
   ],
   "source": [
    "def Recommend(user, train, W, K):\n",
    "    rank = defaultdict(int)\n",
    "    sim_sums = defaultdict(int)\n",
    "    \n",
    "    interacted_items = list(map(lambda p: p[0], train[user]))\n",
    "    for v, wuv in sorted(W[user].items(), key=lambda p: p[1], reverse=True)[0:K]:\n",
    "        for i, rvi in train[v]:\n",
    "            if i in interacted_items:\n",
    "            #we should filter items user interacted before\n",
    "                continue\n",
    "            rank[i] += wuv * rvi\n",
    "            sim_sums[i] += wuv\n",
    "    res = [(sim / 1, i) for i, sim in rank.items()]\n",
    "    res.sort(reverse=True)\n",
    "    ranked_items = [x[1] for x in res]\n",
    "#     sorted(rank.items(), key=lambda p: p[1], reverse=True)\n",
    "    return ranked_items[:50]\n",
    "\n",
    "def Precision(train, test, W, N):\n",
    "    hit = 0\n",
    "    all = 0\n",
    "    for user in test.keys():\n",
    "        tu = list(map(lambda p: p[0], test[user]))\n",
    "        rank = Recommend(user, train, W, N)\n",
    "        for item in rank:\n",
    "            if item in tu:\n",
    "                hit += 1\n",
    "        all += 50\n",
    "    return hit / (all * 1.0)\n",
    "\n",
    "def Recall(train, test, W, N):\n",
    "    hit = 0\n",
    "    all = 0\n",
    "    for user in test.keys():\n",
    "        tu = list(map(lambda p: p[0], test[user]))\n",
    "        rank = Recommend(user, train, W, N)\n",
    "        for item in rank:\n",
    "            if item in tu:\n",
    "                hit += 1\n",
    "        all += len(tu)\n",
    "    return hit / (all * 1.0)\n",
    "\n",
    "def Coverage(train, test, W, N):\n",
    "    recommend_items = set()\n",
    "    all_items = set()\n",
    "    for user in train.keys():\n",
    "        for item, r in test[user]:\n",
    "            all_items.add(item)\n",
    "    for user in test.keys():\n",
    "        rank = Recommend(user, train, W, N)\n",
    "        for item in rank:\n",
    "            recommend_items.add(item)\n",
    "    return len(recommend_items) / (len(all_items) * 1.0)\n",
    "\n",
    "def Popularity(train, test, W, N):\n",
    "    item_popularity = dict()\n",
    "    for user, items in train.items():\n",
    "        for item, r in items:\n",
    "            if item not in item_popularity:\n",
    "                item_popularity[item] = 0\n",
    "            item_popularity[item] += 1\n",
    "    ret = 0\n",
    "    n = 0\n",
    "    for user in test.keys():\n",
    "        rank = Recommend(user, train, W, N)\n",
    "        for item in rank:\n",
    "            ret += np.log(1 + item_popularity[item])\n",
    "            n += 1\n",
    "    ret /= n * 1.0\n",
    "    return ret \n",
    "\n",
    "def eval(train_user_items, test_user_items, W, N):\n",
    "    p = Precision(train_user_items, test_user_items, W, N)\n",
    "    r = Recall(train_user_items, test_user_items, W, N)\n",
    "    c = Coverage(train_user_items, test_user_items, W, N)\n",
    "    pop = Popularity(train_user_items, test_user_items, W, N)\n",
    "    return (p, r, c, pop)\n",
    "    \n",
    "# print(eval(train_user_items, test_user_items, W, 5))\n",
    "print(eval(train_user_items, test_user_items, W, 10))\n",
    "# print(eval(train_user_items, test_user_items, W, 20))\n",
    "# print(eval(train_user_items, test_user_items, W, 30))\n",
    "# print(eval(train_user_items, test_user_items, W, 40))\n",
    "# print(eval(train_user_items, test_user_items, W, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(299, 2500)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.1196, 0.19946631087391595, 0.534020618556701, 1.901404008414894)\n",
    "(0.1316, 0.21947965310206805, 0.35670103092783506, 2.0821030298441956)\n",
    "(0.1368, 0.22815210140093395, 0.25876288659793817, 2.2046577786199233)\n",
    "(0.136, 0.2268178785857238, 0.22783505154639175, 2.264661699694442)\n",
    "(0.1352, 0.22548365577051369, 0.2134020618556701, 2.2836800705995213)\n",
    "(0.134, 0.22348232154769845, 0.2134020618556701, 2.2868977375518935)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost time 0.0021449133333362623 min\n",
      "共现矩阵计算\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:04<00:00, 11.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "相似矩阵计算\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 1694/1694 [00:00<00:00, 4981.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost time 0.08108804666666553 min\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import time\n",
    "import gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "s = time.perf_counter()\n",
    "train = pd.read_csv(r'E:\\ML_study\\学习笔记\\推荐\\movielens\\ml-20m\\ratings_train.csv', engine='python')\n",
    "test = pd.read_csv(r'E:\\ML_study\\学习笔记\\推荐\\movielens\\ml-20m\\ratings_test.csv', engine='python')\n",
    "\n",
    "def combine(data):\n",
    "    item_users = dict()\n",
    "    user_items = dict()\n",
    "    users = set()\n",
    "    data['userId'] = 'user_' + data['userId'].astype(str)\n",
    "    data['movieId'] = 'movie_' + data['movieId'].astype(str)\n",
    "    for u, item, r in data[['userId', 'movieId', 'rating']].values:\n",
    "        item_users.setdefault(item, []).append((u, r))\n",
    "        user_items.setdefault(u, []).append((item, r))\n",
    "        users.add(u)\n",
    "    del data\n",
    "    gc.collect()\n",
    "    return item_users, user_items, users\n",
    "\n",
    "train_item_users, train_user_items, train_users = combine(train)\n",
    "test_item_users, test_user_items, test_users = combine(test)\n",
    "print('cost time %s min' % ((time.perf_counter() - s) / 60))\n",
    "\n",
    "import math\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "def ItemSimilarity(user_items):\n",
    "    # build inverse table for user_items\n",
    "    C = defaultdict(dict)\n",
    "\n",
    "    # item users list\n",
    "    N = defaultdict(int)\n",
    "    print('共现矩阵计算')\n",
    "    for u, pairs in tqdm(user_items.items()):\n",
    "        for i, r1 in pairs:\n",
    "            N[i] += r1 ** 2\n",
    "            for j, r2 in pairs:\n",
    "                if i == j:\n",
    "                    continue\n",
    "                if j not in list(C[i]):\n",
    "                    C[i][j] = 0\n",
    "                C[i][j] += (r1 * r2 / np.log1p(len(pairs)))\n",
    "                \n",
    "    #calculate finial similarity matrix W\n",
    "    W = defaultdict(dict)\n",
    "    print('相似矩阵计算')\n",
    "    for i, related_items in tqdm(C.items()):\n",
    "        for j, cij in related_items.items():\n",
    "            W[i][j] = cij / math.sqrt(N[i] * N[j])\n",
    "            \n",
    "            \n",
    "    # 归一化\n",
    "    for k, v in W.items():\n",
    "        max_w = np.max(list(v.values()))\n",
    "        for j, w in v.items():\n",
    "            v[j] = w / max_w\n",
    "            \n",
    "    return W\n",
    "s = time.perf_counter()\n",
    "W = ItemSimilarity(train_user_items)\n",
    "print('cost time %s min' % ((time.perf_counter() - s) / 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('movie_1073', 0.5617167103983758),\n",
       " ('movie_95', 0.5596002151849775),\n",
       " ('movie_802', 0.5374641747711849),\n",
       " ('movie_786', 0.5222935341726456),\n",
       " ('movie_784', 0.49495500224376193)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(W['movie_1'].items(), key=lambda p: p[1], reverse=True)[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['movie_2567',\n",
       " 'movie_45499',\n",
       " 'movie_1179',\n",
       " 'movie_1127',\n",
       " 'movie_2011',\n",
       " 'movie_6003',\n",
       " 'movie_47044',\n",
       " 'movie_57640',\n",
       " 'movie_54001',\n",
       " 'movie_53464',\n",
       " 'movie_3098',\n",
       " 'movie_2428',\n",
       " 'movie_231',\n",
       " 'movie_150',\n",
       " 'movie_39',\n",
       " 'movie_316',\n",
       " 'movie_296',\n",
       " 'movie_50872',\n",
       " 'movie_40339',\n",
       " 'movie_52287',\n",
       " 'movie_1276',\n",
       " 'movie_4886',\n",
       " 'movie_7373',\n",
       " 'movie_56775',\n",
       " 'movie_55995',\n",
       " 'movie_53125',\n",
       " 'movie_3826',\n",
       " 'movie_4235',\n",
       " 'movie_6863',\n",
       " 'movie_2333',\n",
       " 'movie_1894',\n",
       " 'movie_3827',\n",
       " 'movie_952',\n",
       " 'movie_1302',\n",
       " 'movie_3408',\n",
       " 'movie_54997',\n",
       " 'movie_919',\n",
       " 'movie_468',\n",
       " 'movie_1210',\n",
       " 'movie_59376',\n",
       " 'movie_920',\n",
       " 'movie_1449',\n",
       " 'movie_6942',\n",
       " 'movie_3004',\n",
       " 'movie_852',\n",
       " 'movie_1653',\n",
       " 'movie_2881',\n",
       " 'movie_1097',\n",
       " 'movie_1183',\n",
       " 'movie_35836']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Recommend('user_1', train_user_items, W, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Recommend(user, train, W, K):\n",
    "    rank = defaultdict(int)\n",
    "    \n",
    "    interacted_items = list(map(lambda p: p[0], train[user]))\n",
    "    for item, rji in train[user]:\n",
    "        for j, wij in sorted(W[item].items(), key=lambda p: p[1], reverse=True)[0:K]:\n",
    "            if j in interacted_items:\n",
    "            #we should filter items user interacted before\n",
    "                continue\n",
    "            rank[j] += wij * rji\n",
    "\n",
    "    res = sorted(rank.items(), key=lambda p: p[1], reverse=True)\n",
    "    ranked_items = [x[0] for x in res]\n",
    "    return ranked_items[:50]\n",
    "\n",
    "def Precision(train, test, W, N):\n",
    "    hit = 0\n",
    "    all = 0\n",
    "    for user in test.keys():\n",
    "        tu = list(map(lambda p: p[0], test[user]))\n",
    "        rank = Recommend(user, train, W, N)\n",
    "        for item in rank:\n",
    "            if item in tu:\n",
    "                hit += 1\n",
    "        all += 50\n",
    "    return hit / (all * 1.0)\n",
    "\n",
    "def Recall(train, test, W, N):\n",
    "    hit = 0\n",
    "    all = 0\n",
    "    for user in test.keys():\n",
    "        tu = list(map(lambda p: p[0], test[user]))\n",
    "        rank = Recommend(user, train, W, N)\n",
    "        for item in rank:\n",
    "            if item in tu:\n",
    "                hit += 1\n",
    "        all += len(tu)\n",
    "    return hit / (all * 1.0)\n",
    "\n",
    "def Coverage(train, test, W, N):\n",
    "    recommend_items = set()\n",
    "    all_items = set()\n",
    "    for user in train.keys():\n",
    "        for item, r in test[user]:\n",
    "            all_items.add(item)\n",
    "    for user in test.keys():\n",
    "        rank = Recommend(user, train, W, N)\n",
    "        for item in rank:\n",
    "            recommend_items.add(item)\n",
    "    return len(recommend_items) / (len(all_items) * 1.0)\n",
    "\n",
    "def Popularity(train, test, W, N):\n",
    "    item_popularity = dict()\n",
    "    for user, items in train.items():\n",
    "        for item, r in items:\n",
    "            if item not in item_popularity:\n",
    "                item_popularity[item] = 0\n",
    "            item_popularity[item] += 1\n",
    "    ret = 0\n",
    "    n = 0\n",
    "    for user in test.keys():\n",
    "        rank = Recommend(user, train, W, N)\n",
    "        for item in rank:\n",
    "            ret += np.log(1 + item_popularity[item])\n",
    "            n += 1\n",
    "    ret /= n * 1.0\n",
    "    return ret "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(train_user_items, test_user_items, W, N):\n",
    "    p = Precision(train_user_items, test_user_items, W, N)\n",
    "    r = Recall(train_user_items, test_user_items, W, N)\n",
    "    c = Coverage(train_user_items, test_user_items, W, N)\n",
    "    pop = Popularity(train_user_items, test_user_items, W, N)\n",
    "    return (p, r, c, pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.0696, 0.11607738492328219, 0.5958762886597938, 1.4077830628262402)\n",
      "(0.0716, 0.11941294196130754, 0.6793814432989691, 1.414626173346446)\n",
      "(0.0888, 0.14809873248832556, 0.7061855670103093, 1.4135327850250619)\n",
      "(0.0928, 0.15476984656437626, 0.7587628865979381, 1.4249492106712118)\n",
      "(0.0984, 0.16410940627084722, 0.7721649484536083, 1.4447690762703433)\n",
      "(0.1004, 0.16744496330887257, 0.8164948453608247, 1.431797264092608)\n"
     ]
    }
   ],
   "source": [
    "print(eval(train_user_items, test_user_items, W, 5))\n",
    "print(eval(train_user_items, test_user_items, W, 10))\n",
    "print(eval(train_user_items, test_user_items, W, 20))\n",
    "print(eval(train_user_items, test_user_items, W, 30))\n",
    "print(eval(train_user_items, test_user_items, W, 40))\n",
    "print(eval(train_user_items, test_user_items, W, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(0.0588, 0.0980653769179453, 0.6896907216494845, 1.3641942871593957)\n",
    "(0.066, 0.11007338225483655, 0.7536082474226804, 1.33054347042702)\n",
    "(0.0684, 0.11407605070046697, 0.7175257731958763, 1.3023239552299348)\n",
    "(0.0712, 0.11874583055370247, 0.7164948453608248, 1.2930398697498386)\n",
    "(0.0732, 0.12208138759172782, 0.7453608247422681, 1.26533467745946)\n",
    "(0.0716, 0.11941294196130754, 0.7505154639175258, 1.2386142532419655)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
